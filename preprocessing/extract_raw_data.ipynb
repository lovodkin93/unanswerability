{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "import re\n",
    "import spacy\n",
    "import random\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from scipy.spatial.distance import cosine\n",
    "from collections import Counter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Questions (NQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_UL2 = AutoTokenizer.from_pretrained(\"google/flan-ul2\", model_max_length=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1853969/587612219.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mNQ_data_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr\"../data/NQ/raw/v1.0-simplified_nq-dev-all.jsonl\"\u001b[0m \u001b[0;31m#r\"../data/NQ/raw/full_train/v1.0/train/nq-train-01.jsonl\" #r\"data/NQ/raw/v1.0-simplified_nq-dev-all.jsonl\" # replace in the end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNQ_data_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mNQ_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/adversarial_gpt/lib/python3.7/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NQ_data_dir = r\"../data/NQ/raw/v1.0-simplified_nq-dev-all.jsonl\" #r\"../data/NQ/raw/full_train/v1.0/train/nq-train-01.jsonl\" #r\"data/NQ/raw/v1.0-simplified_nq-dev-all.jsonl\" # replace in the end\n",
    "with open(NQ_data_dir, 'r') as f1:\n",
    "    NQ_data = [json.loads(line) for line in f1.readlines()]\n",
    "\n",
    "\n",
    "\n",
    "# NQ_dev_data_dir=r\"data/NQ/raw/v1.0-simplified_nq-dev-small.jsonl\" #r\"data/NQ/raw/v1.0-simplified_nq-dev-all.jsonl\" # replace in the end\n",
    "# with open(NQ_dev_data_dir, 'r') as f1:\n",
    "#     NQ_dev_data = [json.loads(line) for line in f1.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6150"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(NQ_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_adversarial = True\n",
    "outdir_prefix = \"adversarial\" if is_adversarial else \"control_group\"\n",
    "outdir = os.path.join(r\"../data/NQ\", f\"{outdir_prefix}_NQ.jsonl\") #os.path.join(r\"data/NQ\", f\"{outdir_prefix}_NQ.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NQ_data_small = NQ_data[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check if has unanswerable questions\n",
    "# sum([sum([annotation['long_answer']['start_byte'] >= 0 and not (bool(annotation['short_answers']) or annotation['yes_no_answer'] != 'NONE') for annotation in instance['annotations']]) >= 1 for instance in NQ_data_small])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small_NQ_data_dir = r\"data/NQ/raw/v1.0-simplified_nq-dev-small.jsonl\"\n",
    "# with open(small_NQ_data_dir, 'w') as f1:\n",
    "#     for instance in NQ_data_small:\n",
    "#         f1.write(json.dumps(instance))\n",
    "#         f1.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_embedding(sentence, model, tokenizer):\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\", truncation=True, max_length=512).to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Sentence-BERT model and tokenizer\n",
    "model_name = \"sentence-transformers/paraphrase-distilroberta-base-v1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name).to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|‚ñè         | 100/6150 [00:15<15:08,  6.66it/s]\n"
     ]
    }
   ],
   "source": [
    "full_outputs = []\n",
    "\n",
    "for i,instance in tqdm(enumerate(NQ_data), total=len(NQ_data)): \n",
    "\n",
    "    # taken from https://github.com/google-research-datasets/natural-questions/blob/master/nq_browser.py lines 106-114 and the https://arxiv.org/abs/2211.05655 paper\n",
    "    instances_with_long_answers = [annotation for annotation in instance['annotations'] if annotation['long_answer']['start_byte'] >= 0]\n",
    "    instances_with_short_answers = [annotation for annotation in instances_with_long_answers if bool(annotation['short_answers']) or annotation['yes_no_answer'].upper() != 'NONE']\n",
    "\n",
    "    # if is_adversarial and (len(instances_with_long_answers) == 0 or len(instances_with_short_answers)>=1):\n",
    "    #     continue\n",
    "    if not is_adversarial and len(instances_with_short_answers)==0:\n",
    "        continue\n",
    "    \n",
    "    if is_adversarial:\n",
    "        # filter only long answer candidates that start with <P> (a.k.a paragraphs)\n",
    "        filtered_candidates_indices = [i for i,candidate in enumerate(instance['long_answer_candidates']) if instance['document_tokens'][int(candidate[\"start_token\"])][\"token\"]==\"<P>\"]\n",
    "        \n",
    "        # filter out candidates that were annotated as long answers by at least one of the annotators\n",
    "        annotated_long_answers_indices = set([annotation[\"long_answer\"][\"candidate_index\"] for annotation in instances_with_long_answers])\n",
    "        filtered_candidates_indices = [i for i in filtered_candidates_indices if not i in annotated_long_answers_indices]\n",
    "\n",
    "        if not filtered_candidates_indices: # no paragraphs that weren't annotated as long answers\n",
    "            continue\n",
    "\n",
    "        # get candidates\n",
    "        filtered_candidates = [instance['long_answer_candidates'][i] for i in filtered_candidates_indices]\n",
    "        \n",
    "        # get string paragraphs\n",
    "        filtered_candidates_tokens = [[tkn[\"token\"] for tkn in instance['document_tokens'][int(elem[\"start_token\"]):int(elem[\"end_token\"])]] for elem in filtered_candidates]\n",
    "        filtered_paragraphs = [\" \".join(candidate[1:]) for candidate in filtered_candidates_tokens] # [1:] to remove the <P> token\n",
    "\n",
    "        # Get embeddings for the question and paragraphs\n",
    "        question_embedding = get_sentence_embedding(instance['question_text'], model, tokenizer)\n",
    "        filtered_paragraphs_embedding = [get_sentence_embedding(paragraph, model, tokenizer) for paragraph in filtered_paragraphs]\n",
    "        \n",
    "        # find similarities between each paragraph and the question\n",
    "        similarities = [1 - cosine(question_embedding, p_embedding) for p_embedding in filtered_paragraphs_embedding]\n",
    "        \n",
    "        # choose the paragraph that is the closest to the question in the embedding space\n",
    "        closest_paragraph_ind = np.argmax(similarities)\n",
    "        curr_candidate = filtered_candidates[closest_paragraph_ind]\n",
    "        correct_answer = \"\"\n",
    "        context_start_tkn = curr_candidate['start_token']\n",
    "        context_end_tkn = curr_candidate['end_token']\n",
    "        curr_annotation_id = None\n",
    "        curr_long_answer_candidate_index = filtered_candidates_indices[closest_paragraph_ind]\n",
    "    else:\n",
    "        # filter only annotations that start with <P> (a.k.a paragraphs)\n",
    "        filtered_annotations_indices = [i for i,candidate in enumerate(instances_with_short_answers) if instance['document_tokens'][int(candidate[\"long_answer\"][\"start_token\"])][\"token\"]==\"<P>\"]\n",
    "\n",
    "        if not filtered_annotations_indices: # none of the annotations with short answers was a paragraph\n",
    "            continue\n",
    "\n",
    "        long_answers_candidate_indices = [instances_with_short_answers[i][\"long_answer\"][\"candidate_index\"] for i in filtered_annotations_indices]\n",
    "        prev_len = len(long_answers_candidate_indices)\n",
    "        long_answers_candidate_indices = [cand_ind for cand_ind in long_answers_candidate_indices if not \"<table>\" in \" \".join([tkn[\"token\"] for tkn in instance['document_tokens'][int(instance['long_answer_candidates'][cand_ind][\"start_token\"]):int(instance['long_answer_candidates'][cand_ind][\"end_token\"])]]).lower()]\n",
    "        \n",
    "        if not filtered_annotations_indices:\n",
    "            continue\n",
    "\n",
    "        long_answers_candidate_indices_cnt = Counter(long_answers_candidate_indices)\n",
    "        best_long_answers_candidate_index, _ = long_answers_candidate_indices_cnt.most_common(1)[0]\n",
    "        annotation_ind = long_answers_candidate_indices.index(best_long_answers_candidate_index)\n",
    "        annotation_ind = filtered_annotations_indices[annotation_ind]\n",
    "        curr_annotation = instances_with_short_answers[annotation_ind]\n",
    "\n",
    "        if curr_annotation[\"yes_no_answer\"].upper() != \"NONE\":\n",
    "            correct_answer = curr_annotation[\"yes_no_answer\"]\n",
    "        else:\n",
    "            answer_start_tkn = curr_annotation['short_answers'][0]['start_token']\n",
    "            answer_end_tkn = curr_annotation['short_answers'][0]['end_token']\n",
    "            correct_answer = \" \".join([elem[\"token\"] for elem in instance['document_tokens'][answer_start_tkn:answer_end_tkn]])\n",
    "    \n",
    "        context_start_tkn = curr_annotation['long_answer']['start_token']\n",
    "        context_end_tkn = curr_annotation['long_answer']['end_token']\n",
    "        curr_annotation_id = curr_annotation['annotation_id']\n",
    "        curr_long_answer_candidate_index = curr_annotation['long_answer'][\"candidate_index\"]\n",
    "\n",
    "    paragraph_text = \" \".join([elem[\"token\"] for elem in instance['document_tokens'][context_start_tkn:context_end_tkn]]).replace(\"<P>\", \"\").replace(\"</P>\", \"\").strip()\n",
    "    question_text = instance['question_text']\n",
    "    paragraph_tkns = tokenizer_UL2.encode(paragraph_text)\n",
    "    question_tkns = tokenizer_UL2.encode(question_text)\n",
    "    if len(paragraph_tkns) + len(question_tkns) > 400: # to accomodate also the instructions\n",
    "        continue\n",
    "\n",
    "    full_outputs.append({\"example_id\": instance['example_id'],\n",
    "                         \"annotation_id\": curr_annotation_id,\n",
    "                         \"long_answer_candidate\": curr_long_answer_candidate_index,\n",
    "                         \"Question\": question_text,\n",
    "                         \"Paragraphs\": paragraph_text,\n",
    "                         \"answer\": correct_answer})\n",
    "    # # for the train data (for the classifiers)\n",
    "    if len(full_outputs) >= 2000:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1642"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(outdir, 'w') as f1:\n",
    "    f1.write(json.dumps(full_outputs, indent=2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Musique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_UL2 = AutoTokenizer.from_pretrained(\"google/flan-ul2\", model_max_length=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "musique_data_dir = r\"../data/musique/raw/data/musique_full_v1.0_dev.jsonl\" #r\"data/musique/raw/data/musique_full_v1.0_train.jsonl\" \n",
    "with open(musique_data_dir, 'r') as f1:\n",
    "    musique_data = [json.loads(line) for line in f1.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = [\"\\n\".join([p[\"paragraph_text\"] for p in instance[\"paragraphs\"]]) for instance in musique_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs_tkn = [tokenizer_UL2.encode(paragraph_text) for paragraph_text in paragraphs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs_tkn_len = [len(elem) for elem in paragraphs_tkn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs_tkn_len_small = [elem for elem in paragraphs_tkn_len if elem<2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11921"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paragraphs_tkn_len_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_embedding(sentence, model, tokenizer):\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Sentence-BERT model and tokenizer\n",
    "model_name = \"sentence-transformers/paraphrase-distilroberta-base-v1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_paragaph_ind(qa_embedding, paragraphs_embedding):\n",
    "    # find similarities between each paragraph and the question\n",
    "    similarities = [1 - cosine(qa_embedding, p_embedding) for p_embedding in paragraphs_embedding]\n",
    "    \n",
    "    # choose the paragraph that is the closest to the question in the embedding space\n",
    "    return np.argmax(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/4834 [07:27<236:07:25, 175.99s/it]"
     ]
    }
   ],
   "source": [
    "answerable = []\n",
    "unanswerable = []\n",
    "for instance in tqdm(musique_data):\n",
    "    if instance[\"answerable\"]:\n",
    "        curr_paragraphs = [p[\"paragraph_text\"] for p in instance['paragraphs'] if p[\"is_supporting\"]]\n",
    "        curr_paragraphs = \"\\n \".join([f\"Paragraph {i+1}: {p}\" for i,p in enumerate(curr_paragraphs)])\n",
    "        answerable.append({\"id\": instance['id'],\n",
    "                            \"Question\": instance['question'],\n",
    "                            \"Paragraphs\": curr_paragraphs,\n",
    "                            \"answer\": instance['answer']})\n",
    "    else:\n",
    "        curr_qa_decomposition = [q[\"question\"] for q in instance['question_decomposition']]\n",
    "        curr_qa_decomposition = curr_qa_decomposition + [q[\"answer\"] for q in instance['question_decomposition']]\n",
    "\n",
    "        curr_qa_decomposition_embed = [get_sentence_embedding(qa, model, tokenizer) for qa in curr_qa_decomposition]\n",
    "        curr_paragraphs_embed = [get_sentence_embedding(p[\"paragraph_text\"], model, tokenizer) for p in instance['paragraphs']]\n",
    "        closest_paragaphs_ind = [get_closest_paragaph_ind(qa_embedding, curr_paragraphs_embed) for qa_embedding in curr_qa_decomposition_embed]\n",
    "        closest_paragaphs_ind = set(closest_paragaphs_ind)\n",
    "        curr_paragraphs = [instance['paragraphs'][paragraph_i][\"paragraph_text\"] for paragraph_i in closest_paragaphs_ind]\n",
    "        curr_paragraphs = \"\\n \".join([f\"Paragraph {i+1}: {p}\" for i,p in enumerate(curr_paragraphs)])\n",
    "\n",
    "        # take only not too long instances\n",
    "        curr_paragraphs_tkns = tokenizer_UL2.encode(curr_paragraphs)\n",
    "        if len(curr_paragraphs_tkns)>500:\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        unanswerable.append({\"id\": instance['id'],\n",
    "                            \"Question\": instance['question'],\n",
    "                            \"Paragraphs\": curr_paragraphs,\n",
    "                            \"answer\": \"\",\n",
    "                            \"actual_answer\":instance['answer']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "answerable_outdir = \"data/musique/control_group_musique_train.jsonl\"\n",
    "unanswerable_outdir = \"data/musique/adversarial_musique_train.jsonl\"\n",
    "\n",
    "with open(answerable_outdir, 'w') as f1:\n",
    "    f1.write(json.dumps(answerable, indent=2))\n",
    "\n",
    "with open(unanswerable_outdir, 'w') as f1:\n",
    "    f1.write(json.dumps(unanswerable, indent=2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter out the long instances (musique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "answerable_outdir = \"data/musique/control_group_musique_train.jsonl\" #\"data/musique/control_group_musique.jsonl\"\n",
    "unanswerable_outdir = \"data/musique/adversarial_musique_train.jsonl\" #\"data/musique/adversarial_musique.jsonl\"\n",
    "\n",
    "with open(answerable_outdir, 'r') as f1:\n",
    "    control_group_data = json.loads(f1.read())\n",
    "\n",
    "with open(unanswerable_outdir, 'r') as f1:\n",
    "    adversarial_data = json.loads(f1.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_group_data_filtered = [instance for instance in control_group_data if len(tokenizer_UL2.encode(instance[\"Paragraphs\"]))<=500]\n",
    "adversarial_data_filtered = [instance for instance in adversarial_data if len(tokenizer_UL2.encode(instance[\"Paragraphs\"]))<=500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17871"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(control_group_data_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(answerable_outdir, 'w') as f1:\n",
    "    f1.write(json.dumps(control_group_data_filtered, indent=2))\n",
    "\n",
    "with open(unanswerable_outdir, 'w') as f1:\n",
    "    f1.write(json.dumps(adversarial_data_filtered, indent=2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract (all annotated) Responses for NQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indir_NQ_raw = \"data/NQ/raw/v1.0-simplified_nq-dev-all.jsonl\"\n",
    "indir_extracted_control_group_NQ = \"data/NQ/control_group_NQ.jsonl\"\n",
    "indir_extracted_adversarial_NQ = \"data/NQ/adversarial_NQ.jsonl\"\n",
    "\n",
    "outdir_all_responses_NQ = \"data/NQ/NQ_answers.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(indir_NQ_raw, 'r') as f1:\n",
    "    NQ_data_raw = [json.loads(line) for line in f1.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(indir_extracted_control_group_NQ, 'r') as f1:\n",
    "    NQ_data_extracted = json.loads(f1.read())\n",
    "    extracted_ids = {elem[\"example_id\"]:elem[\"annotation_id\"] for elem in NQ_data_extracted}\n",
    "    extracted_example_ids = list(extracted_ids.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NQ_data_raw = NQ_data[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_group_output_dict = dict()\n",
    "for i,instance in tqdm(enumerate(NQ_data), total=len(NQ_data_raw)): \n",
    "    if not instance[\"example_id\"] in extracted_example_ids:\n",
    "        continue\n",
    "    # if any(annotation[\"yes_no_answer\"].upper() != \"NONE\" for annotation in instance[\"annotations\"]):\n",
    "    #     if not all(annotation[\"yes_no_answer\"].upper() != \"NONE\" for annotation in instance[\"annotations\"]):\n",
    "    #         print(\"gotcha\")\n",
    "    curr_annotation_id = extracted_ids[instance[\"example_id\"]]\n",
    "    curr_long_answer_candidate = [annotation[\"long_answer\"][\"candidate_index\"] for annotation in instance[\"annotations\"] if annotation[\"annotation_id\"]==curr_annotation_id][0]\n",
    "    answers_limits = [(short_answer[\"start_token\"], short_answer[\"end_token\"]) for annotation in instance[\"annotations\"] for short_answer in annotation[\"short_answers\"] if annotation[\"long_answer\"][\"candidate_index\"]==curr_long_answer_candidate]\n",
    "    all_answers = [\" \".join([tkn[\"token\"] for tkn in instance['document_tokens'][s:e]]) for s,e in answers_limits]\n",
    "    yes_no_answers = [annotation[\"yes_no_answer\"] for annotation in instance[\"annotations\"] if annotation[\"yes_no_answer\"].upper() != \"NONE\" and annotation[\"long_answer\"][\"candidate_index\"]==curr_long_answer_candidate]\n",
    "    all_answers.extend(yes_no_answers)\n",
    "    all_answers = list(set(all_answers))\n",
    "    control_group_output_dict[instance[\"example_id\"]] = all_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(indir_extracted_adversarial_NQ, 'r') as f1:\n",
    "    adversarial_NQ_data_extracted = json.loads(f1.read())\n",
    "    adversarial_output_dict = {f\"{instance['example_id']}-unanswerable\":\"\" for instance in adversarial_NQ_data_extracted}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check (make sure no \"overlapping\" keys)\n",
    "set(adversarial_output_dict.keys()).intersection(set(control_group_output_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine answerable and unanswerable questions\n",
    "adversarial_output_dict.update(control_group_output_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(outdir_all_responses_NQ, 'w') as f1:\n",
    "    f1.write(json.dumps(adversarial_output_dict))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Responses for musique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "indir_extracted_control_group_musique = \"data/musique/control_group_musique.jsonl\"\n",
    "indir_extracted_adversarial_musique = \"data/musique/adversarial_musique.jsonl\"\n",
    "\n",
    "outdir_all_responses_musique = \"data/musique/musique_answers.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(indir_extracted_control_group_musique, 'r') as f1:\n",
    "    extracted_control_group_musique = json.loads(f1.read())\n",
    "\n",
    "with open(indir_extracted_adversarial_musique, 'r') as f1:\n",
    "    extracted_adversarial_musique = json.loads(f1.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '2hop__153573_109006',\n",
       " 'Question': \"Who developed the eponymous character from the series that contains Mickey's Safari in Letterland?\",\n",
       " 'Paragraphs': \"Paragraph 1: The White armored car was a series of armored cars developed by the White Motor Company in Cleveland, Ohio from 1915.\\n Paragraph 2: The 100 (pronounced The Hundred) is an American post-apocalyptic science fiction drama television series developed by Jason Rothenberg, which premiered on March 19, 2014, on The CW. It is loosely based on a 2013 book of the same name, the first in a book series by Kass Morgan. The series follows a group of teens as they become the first people from a space habitat to return to Earth after a devastating nuclear apocalypse.\\n Paragraph 3: Parc Safari is a zoo in Hemmingford, Quebec, Canada, and is one of the region's major tourist attractions; that has both African & Asian species of elephant.\",\n",
       " 'answer': '',\n",
       " 'actual_answer': 'Walt Disney'}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_adversarial_musique[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "musique_control_group_dict = {instance[\"id\"]:[instance[\"answer\"]] for instance in extracted_control_group_musique}\n",
    "musique_adversarial_dict = {f\"{instance['id']}-unanswerable\":\"\" for instance in extracted_adversarial_musique}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check (make sure no \"overlapping\" keys)\n",
    "set(musique_control_group_dict.keys()).intersection(set(musique_adversarial_dict.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine answerable and unanswerable questions\n",
    "musique_adversarial_dict.update(musique_control_group_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(outdir_all_responses_musique, 'w') as f1:\n",
    "        f1.write(json.dumps(musique_adversarial_dict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adversarial_gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
